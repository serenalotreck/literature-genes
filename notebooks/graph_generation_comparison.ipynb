{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph generation comparison\n",
    "In this notebook, we'll compare the outputs of a few different approaches to  graph building for characteristics like degree skew and entity grounding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "import pandas as pd\n",
    "from ontogpt.io.csv_wrapper import parse_yaml_predictions\n",
    "from os import listdir\n",
    "from os.path import splitext\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from random import sample\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_path = '../knowledge_graph/schema/desiccation.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 926/926 [00:00<00:00, 117346.23it/s]\n"
     ]
    }
   ],
   "source": [
    "onto_full_ents, onto_full_rels = parse_yaml_predictions('../data/ontogpt_output/test_1000_full/output.txt', schema_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 929/929 [00:00<00:00, 105004.54it/s]\n"
     ]
    }
   ],
   "source": [
    "onto_slim_ents, onto_slim_rels = parse_yaml_predictions('../data/ontogpt_output/test_1000_slim/output.txt', schema_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "uids_to_keep = [splitext(f)[0] for f in listdir('/mnt/scratch/lotrecks/drought_and_des_1000_subset_15Apr2024/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with jsonlines.open('../data/dygiepp/model_predictions/09Apr24_dygiepp_test_formatted_data_pickle_predictions.jsonl') as reader:\n",
    "    dygiepp = [obj for obj in reader if obj['doc_key'] in uids_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data\n",
    "Convert DyGIE++ to csv, then all three to networkx objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dygiepp_ents = {'id': [], 'category': [], 'name': [], 'provided_by': []}\n",
    "dygiepp_rels = {'id': [], 'category': [], 'provided_by': [], 'predicate': [], 'subject': [], 'object': []}\n",
    "for doc in dygiepp:\n",
    "    all_text = [tok for sent in doc['sentences'] for tok in sent]\n",
    "    for sent in doc['predicted_ner']:\n",
    "        for ent in sent:\n",
    "            dygiepp_ents['id'].append(np.nan)\n",
    "            dygiepp_ents['category'].append(ent[2])\n",
    "            dygiepp_ents['name'].append(' '.join(all_text[ent[0]: ent[1]+1]).lower())\n",
    "            dygiepp_ents['provided_by'].append(doc['doc_key'])\n",
    "    for sent in doc['predicted_relations']:\n",
    "        for rel in sent:\n",
    "            dygiepp_rels['id'].append(np.nan)\n",
    "            dygiepp_rels['category'].append(rel[4])\n",
    "            dygiepp_rels['provided_by'].append(doc['doc_key'])\n",
    "            dygiepp_rels['predicate'].append(rel[4])\n",
    "            dygiepp_rels['subject'].append(' '.join(all_text[rel[0]: rel[1]+1]).lower())\n",
    "            dygiepp_rels['object'].append(' '.join(all_text[rel[2]: rel[3]+1]).lower())\n",
    "dygiepp_ent_df = pd.DataFrame(dygiepp_ents)\n",
    "dygiepp_rel_df = pd.DataFrame(dygiepp_rels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kgx_to_networkx(ent_df, rel_df, source='onto'):\n",
    "    \"\"\"\n",
    "    Convert two KGX-formatted df's into a networkx graph.\n",
    "    \"\"\"\n",
    "    if source == 'onto':\n",
    "        nodes = [(row.id, {'ent_type': row.category, 'name': row['name']}) for i, row in ent_df.iterrows()]\n",
    "    else:\n",
    "        nodes = [(row.name, {'ent_type': row.category}) for i, row in ent_df.iterrows()]\n",
    "    edges = [(row.subject, row.object, {'rel_type': row.predicate}) for i, row in rel_df.iterrows()]\n",
    "    graph = nx.DiGraph()\n",
    "    _ = graph.add_nodes_from(nodes)\n",
    "    _ = graph.add_edges_from(edges)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dygiepp_graph = kgx_to_networkx(dygiepp_ent_df, dygiepp_rel_df, source='dygiepp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "onto_slim_graph = kgx_to_networkx(onto_slim_ents, onto_slim_rels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "onto_full_graph = kgx_to_networkx(onto_full_ents, onto_full_rels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nets = {\n",
    "    'dygiepp': dygiepp_graph,\n",
    "    'onto_slim': onto_slim_graph,\n",
    "    'onto_full': onto_full_graph\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic network statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In network dygiepp, there are 18360 nodes and 1448 edges.\n",
      "In network onto_slim, there are 2940 nodes and 770 edges.\n",
      "In network onto_full, there are 2893 nodes and 692 edges.\n"
     ]
    }
   ],
   "source": [
    "for net_name, net in nets.items():\n",
    "    print(f'In network {net_name}, there are {len(net.nodes)} nodes and {len(net.edges)} edges.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of edges is bad in all methods, but OntoGPT extracts orders of magnitude more entities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check relation quality\n",
    "A previous glance at the DyGIE++ relations showed that the majority of them were trivial -- we'll take a look at a few sets of triples from each graph to get an idea of whether or not they're meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ten random triples from dygiepp:\n",
      "----------------------------------------------------\n",
      "('pri', 'activates', 'c')\n",
      "('abscisic acid and jasmonic acid signaling pathways', 'is-in', 'da92 - 2f6')\n",
      "('nsc', 'is-in', 'oak and beech saplings')\n",
      "('lea proteins', 'is-in', 'p. edulis')\n",
      "('snrk2 gene family', 'is-in', 'zea mays')\n",
      "('phenylethanoid glycosides', 'is-in', 'scrophularia striate')\n",
      "('dfi', 'inhibits', 'sorghum')\n",
      "('water', 'inhibits', 'f-ty')\n",
      "('aba', 'interacts', 'vacuolar na+ sequestration')\n",
      "('beta- hydroxyethylhydrazine', 'inhibits', 'polyamine')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Ten random triples from onto_slim:\n",
      "----------------------------------------------------\n",
      "('TGFβ', 'GeneGeneInteraction', 'SMAD3')\n",
      "('NFYA5', 'GeneProteinInteraction', 'NF-YC')\n",
      "('not provided', 'GeneOrganismRelationship', 'cv. Hira')\n",
      "('sORFs', 'GeneMoleculeInteraction', 'NA')\n",
      "('SAMDC', 'GeneProteinInteraction', 'H+-ATPase')\n",
      "('BDN1', 'GeneOrganismRelationship', 'Boea crassifolia Hemsl')\n",
      "('PCK', 'GeneProteinInteraction', 'CA')\n",
      "('CKS2', 'GeneProteinInteraction', 'beta-glucuronidase')\n",
      "('TaPLC1', 'GeneMoleculeInteraction', 'edelfosine')\n",
      "('IACSP 95-5000', 'GeneOrganismRelationship', 'genotype')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Ten random triples from onto_full:\n",
      "----------------------------------------------------\n",
      "('nitrite reductase', 'ProteinProteinInteraction', 'glutamine synthetase')\n",
      "('NFYA5', 'GeneMoleculeInteraction', 'ABA')\n",
      "('IVR1-5B', 'GeneOrganismRelationship', 'wheat (Triticum aestivum L.)')\n",
      "('NRGA1', 'GeneOrganismRelationship', 'Arabidopsis thaliana')\n",
      "('groundwater', 'GeneMoleculeInteraction', '(blank)')\n",
      "('ZmHDZ9', 'GeneProteinInteraction', 'SOD')\n",
      "('Not provided', 'GeneOrganismRelationship', 'Triticum aestivum Linn.')\n",
      "('HaNAC3', 'GeneProteinInteraction', 'GFP')\n",
      "('NF-YC', 'ProteinOrganismRelationship', 'Arabidopsis thaliana')\n",
      "('Butein', 'ProteinOrganismRelationship', 'Butea monosperma')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for net_name, net in nets.items():\n",
    "    trips = [(e1, attrs['rel_type'], e2) for e1, e2, attrs in net.edges(data=True)]\n",
    "    if net_name in ['onto_slim', 'onto_full']:\n",
    "        id2name = nx.get_node_attributes(net, 'name')\n",
    "        updated_trips = []\n",
    "        for e1, rt, e2 in trips:\n",
    "            try:\n",
    "                updated_trip = (id2name[e1], rt, id2name[e2])\n",
    "                updated_trips.append(updated_trip)\n",
    "            except KeyError:\n",
    "                continue\n",
    "        trips = updated_trips\n",
    "    to_print = sample(trips, 10)\n",
    "    print(f'Ten random triples from {net_name}:')\n",
    "    print('----------------------------------------------------')\n",
    "    for trip in to_print:\n",
    "        print(trip)\n",
    "    print('\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These actually don't look bad at all! Certainly there are not enough of them, and there are a fair share of relations involving NaN or nonsense characters on the part of OntoGPT, but much less bad than I expected overall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check grounding percentages and entity recovery for the slim and full OntoGPT versions\n",
    "I'm concerned that the slim version, while faster, results in substantially more entities not getting a grounding, so we want to check that here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "slim_groundings = onto_slim_ents[['name', 'id', 'category']].copy()\n",
    "slim_groundings['name'] = slim_groundings['name'].str.lower()\n",
    "slim_groundings = slim_groundings.drop_duplicates().reset_index(drop=True)\n",
    "full_groundings = onto_full_ents[['name', 'id', 'category']].copy()\n",
    "full_groundings['name'] = full_groundings['name'].str.lower()\n",
    "full_groundings = full_groundings.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "For slim OntoGPT:\n",
      "There are 2939 unique entities.\n",
      "Number of entities grounded to each ontology:\n",
      "   CHEBI : 348\n",
      "   NCBITaxon : 285\n",
      "   AUTO : 2181\n",
      "   GO : 29\n",
      "   PR : 96\n",
      "\n",
      "\n",
      "For full OntoGPT:\n",
      "There are 2892 unique entities.\n",
      "Number of entities grounded to each ontology:\n",
      "   CHEBI : 328\n",
      "   NCBITaxon : 500\n",
      "   AUTO : 1944\n",
      "   GO : 34\n",
      "   PR : 86\n"
     ]
    }
   ],
   "source": [
    "for ty, gr in {'slim': slim_groundings, 'full': full_groundings}.items():\n",
    "    print(f'\\n\\nFor {ty} OntoGPT:')\n",
    "    print(f'There are {len(gr)} unique entities.')\n",
    "    labs = gr.id.values.tolist()\n",
    "    counted_prefixes = Counter([i.split(':')[0] for i in labs])\n",
    "    print('Number of entities grounded to each ontology:')\n",
    "    for ont, num in counted_prefixes.items():\n",
    "        print('  ', ont, ':', num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's looking like changing over to the slim NCBI Taxonomy resulted in a loss of almost half of the species groundings. Let's take a more detailed look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_groundings = slim_groundings.merge(full_groundings, how='outer', on='name', suffixes=('_slim', '_full'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id_slim</th>\n",
       "      <th>category_slim</th>\n",
       "      <th>id_full</th>\n",
       "      <th>category_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>arabidopsis thaliana</td>\n",
       "      <td>NCBITaxon:3702</td>\n",
       "      <td>Organism</td>\n",
       "      <td>AUTO:Arabidopsis%20thaliana</td>\n",
       "      <td>Gene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>arabidopsis thaliana</td>\n",
       "      <td>AUTO:Arabidopsis%20thaliana</td>\n",
       "      <td>Gene</td>\n",
       "      <td>NCBITaxon:3702</td>\n",
       "      <td>Organism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>cotton</td>\n",
       "      <td>NCBITaxon:3635</td>\n",
       "      <td>Organism</td>\n",
       "      <td>AUTO:cotton</td>\n",
       "      <td>Molecule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>cotton</td>\n",
       "      <td>AUTO:cotton</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>NCBITaxon:3635</td>\n",
       "      <td>Organism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>rice</td>\n",
       "      <td>NCBITaxon:4530</td>\n",
       "      <td>Organism</td>\n",
       "      <td>AUTO:Rice</td>\n",
       "      <td>UNKNOWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3014</th>\n",
       "      <td>xylella fastidiosa</td>\n",
       "      <td>AUTO:Xylella%20fastidiosa</td>\n",
       "      <td>Gene</td>\n",
       "      <td>NCBITaxon:2371</td>\n",
       "      <td>Organism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3015</th>\n",
       "      <td>xylella fastidiosa</td>\n",
       "      <td>NCBITaxon:2371</td>\n",
       "      <td>Organism</td>\n",
       "      <td>AUTO:Xylella%20fastidiosa</td>\n",
       "      <td>Gene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3063</th>\n",
       "      <td>hippophae rhamnoides</td>\n",
       "      <td>AUTO:Hippophae%20rhamnoides</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>NCBITaxon:193516</td>\n",
       "      <td>Organism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3082</th>\n",
       "      <td>biochar</td>\n",
       "      <td>AUTO:biochar</td>\n",
       "      <td>Organism</td>\n",
       "      <td>AUTO:biochar</td>\n",
       "      <td>Molecule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3159</th>\n",
       "      <td>nostoc sp.</td>\n",
       "      <td>AUTO:Nostoc%20sp.</td>\n",
       "      <td>Organism</td>\n",
       "      <td>AUTO:Nostoc%20sp.</td>\n",
       "      <td>Gene</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name                      id_slim category_slim  \\\n",
       "16    arabidopsis thaliana               NCBITaxon:3702      Organism   \n",
       "17    arabidopsis thaliana  AUTO:Arabidopsis%20thaliana          Gene   \n",
       "46                  cotton               NCBITaxon:3635      Organism   \n",
       "47                  cotton                  AUTO:cotton       UNKNOWN   \n",
       "62                    rice               NCBITaxon:4530      Organism   \n",
       "...                    ...                          ...           ...   \n",
       "3014    xylella fastidiosa    AUTO:Xylella%20fastidiosa          Gene   \n",
       "3015    xylella fastidiosa               NCBITaxon:2371      Organism   \n",
       "3063  hippophae rhamnoides  AUTO:Hippophae%20rhamnoides       UNKNOWN   \n",
       "3082               biochar                 AUTO:biochar      Organism   \n",
       "3159            nostoc sp.            AUTO:Nostoc%20sp.      Organism   \n",
       "\n",
       "                          id_full category_full  \n",
       "16    AUTO:Arabidopsis%20thaliana          Gene  \n",
       "17                 NCBITaxon:3702      Organism  \n",
       "46                    AUTO:cotton      Molecule  \n",
       "47                 NCBITaxon:3635      Organism  \n",
       "62                      AUTO:Rice       UNKNOWN  \n",
       "...                           ...           ...  \n",
       "3014               NCBITaxon:2371      Organism  \n",
       "3015    AUTO:Xylella%20fastidiosa          Gene  \n",
       "3063             NCBITaxon:193516      Organism  \n",
       "3082                 AUTO:biochar      Molecule  \n",
       "3159            AUTO:Nostoc%20sp.          Gene  \n",
       "\n",
       "[130 rows x 5 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "organisms = merged_groundings[(merged_groundings['category_slim'] == 'Organism') | (merged_groundings['category_full'] == 'Organism')]\n",
    "overlapping_organisms = organisms.dropna()\n",
    "mismatched_organisms = overlapping_organisms[overlapping_organisms['category_slim'] != overlapping_organisms['category_full']]\n",
    "mismatched_organisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ontogpt",
   "language": "python",
   "name": "ontogpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
