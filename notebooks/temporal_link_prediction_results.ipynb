{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link prediction results\n",
    "In this notebook, we'll look at the results of our STHN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/home/lotrecks/anaconda3/envs/sthn/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/mnt/home/lotrecks/anaconda3/envs/sthn/lib/python3.9/site-packages/torch_geometric/typing.py:99: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /lib64/libm.so.6: version `GLIBC_2.27' not found (required by /mnt/ufs18/home-118/lotrecks/anaconda3/envs/sthn/lib/python3.9/site-packages/torch_spline_conv/_basis_cuda.so)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('../../STHN/')\n",
    "from model import Multiclass_Interface as STHN_Interface\n",
    "from construct_subgraph import get_parallel_sampler, get_mini_batch\n",
    "from link_pred_train_utils import compute_sign_feats\n",
    "from data_process_utils import get_random_inds\n",
    "from utils import load_feat\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in & plot the per-epoch performance values\n",
    "Unfortunately, the code doesn't have an option to save the epoch performance values as anything, the only option is to direct the `stdout` to a file, so we'll need to define our own little parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../job_scripts/sthn_dt_24h.o') as f:\n",
    "    performance_vals = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'>>> Epoch  50'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_vals[-1] # Overall score is last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epoch_perf(performance_vals):\n",
    "    ep_idxs = {}\n",
    "    for i, line in enumerate(performance_vals):\n",
    "        if line[:9] == '>>> Epoch':\n",
    "            ep_num = int(line[10:])\n",
    "            ep_idxs[ep_num] = i\n",
    "    ep_perfs = defaultdict(dict)\n",
    "    for ep_num, idx in ep_idxs.items():\n",
    "        for i, mode in enumerate(['train', 'valid', 'test']):\n",
    "            type_perfs = {}\n",
    "            perfs = performance_vals[idx + i + 1].split(', ')\n",
    "            for perf in perfs:\n",
    "                if len(perf.split()) == 2:\n",
    "                    type_perfs[perf.split()[0]] = float(perf.split()[1])\n",
    "            ep_perfs[ep_num][mode] = type_perfs\n",
    "    return ep_perfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m epoch_performances \u001b[38;5;241m=\u001b[39m \u001b[43mget_epoch_perf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperformance_vals\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m, in \u001b[0;36mget_epoch_perf\u001b[0;34m(performance_vals)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m     10\u001b[0m     type_perfs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 11\u001b[0m     perfs \u001b[38;5;241m=\u001b[39m \u001b[43mperformance_vals\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m perf \u001b[38;5;129;01min\u001b[39;00m perfs:\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(perf\u001b[38;5;241m.\u001b[39msplit()) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "epoch_performances = get_epoch_perf(performance_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aurocs = {k: v['train']['AUROC'] for k, v in epoch_performances.items()}\n",
    "train_losses = {k: v['train']['loss'] for k, v in epoch_performances.items()}\n",
    "valid_aurocs = {k: v['valid']['AUROC'] for k, v in epoch_performances.items()}\n",
    "valid_losses = {k: v['valid']['loss'] for k, v in epoch_performances.items()}\n",
    "test_aurocs = {k: v['test']['AUROC'] for k, v in epoch_performances.items()}\n",
    "test_losses = {k: v['test']['loss'] for k, v in epoch_performances.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax1.plot(train_aurocs.keys(), train_aurocs.values(), color='blue', label='Training')\n",
    "ax1.plot(valid_aurocs.keys(), valid_aurocs.values(), color='blue', linestyle='dotted', label='Validation')\n",
    "ax1.plot(test_aurocs.keys(), test_aurocs.values(), color='blue', linestyle='dashed', label='Test')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "ax1.set_ylim(0, 1)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(train_losses.keys(), train_losses.values(), color='green', label='Training')\n",
    "ax2.plot(valid_losses.keys(), valid_losses.values(), color='green', linestyle='dotted', label='Validation')\n",
    "ax2.plot(test_losses.keys(), test_losses.values(), color='green', linestyle='dashed', label='Test')\n",
    "ax2.tick_params(axis='y', labelcolor='green')\n",
    "ax2.set_ylim(0, 1)\n",
    "\n",
    "ax1.set_ylabel('AUROC', color='blue')\n",
    "ax2.set_ylabel('Loss', color='Green')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.legend(loc='lower left')\n",
    "leg = ax1.get_legend()\n",
    "for i in range(3):\n",
    "    leg.legend_handles[i].set_color('black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine test set predictions\n",
    "We've saved the prediction tensors for both edges and edge labels from the STHN code. The STHN code does not turn these predictions into human-readable forms, so here, we will explore the possibility of doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = torch.load('../../STHN/DATA/drought_desiccation/model_predictions/test_epoch_0_pred_tensors.pt', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([838, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(test_preds[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use trained model to make predictions for 2024\n",
    "The STHN code doesn't have a built-in way to make actual rpedictions, so I added a line of code to save the model. Here, we'll read it in and make predictions for 2024, so we can examine them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to set up the configs required by the model class. I added a print statement to print out the values for both dictionaries so we can just paste them here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_predictor_configs = {'dim_in_time': 100,\n",
    "                          'dim_in_node': 0,\n",
    "                          'predict_class': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixer_configs =  {'per_graph_size': 50,\n",
    "                  'time_channels': 100,\n",
    "                  'input_channels': 3,\n",
    "                  'hidden_channels': 100,\n",
    "                  'out_channels': 100,\n",
    "                  'num_layers': 1,\n",
    "                  'dropout': 0.1,\n",
    "                  'channel_expansion_factor': 2,\n",
    "                  'window_size': 5,\n",
    "                  'use_single_layer': False}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I try to load the state dict into an STHN model initialized with the above parameters, I get a size mismatch error. According to [this stackoverflow post](https://stackoverflow.com/questions/67838192/size-mismatch-runtime-error-when-trying-to-load-a-pytorch-model), this means my model was trained on a different number of classes than the one I just instantiated. Since I instantiated it with the same exact parameters here as were used during trainng, I find this odd. However, one of [the answers](https://stackoverflow.com/a/76154523/13340814) offers a way to bypass any weights that have shape mismatches. Let's try it and see how many we had to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_state_dict = torch.load('../../STHN/DATA/drought_desiccation/trained_dt_model')\n",
    "sthn_model = STHN_Interface(mixer_configs, edge_predictor_configs)\n",
    "current_model_dict = sthn_model.state_dict()\n",
    "new_state_dict = {k:v if v.size()==current_model_dict[k].size()  else  current_model_dict[k] for k,v in zip(current_model_dict.keys(), loaded_state_dict.values())}\n",
    "sthn_model.load_state_dict(new_state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 32 total parameters.\n"
     ]
    }
   ],
   "source": [
    "for k,v in zip(current_model_dict.keys(), loaded_state_dict.values()):\n",
    "    if not v.size() == current_model_dict[k].size():\n",
    "        print(f'Weight {k} was loaded from new model.')\n",
    "print(f'There are {len(new_state_dict)} total parameters.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only two of the 32 parameters had a size mismatch issue. For now I will use this loaded model, but I will come back to see if I can figure out what's going on there later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line that computes predictions in the STHN code is:\n",
    "\n",
    "```\n",
    "loss, pred, edge_label = model(inputs, neg_samples, subgraph_node_feats)\n",
    "```\n",
    "\n",
    "Let's see if we can figure out what the format of all those elements should be, and see if we can make a prediction on the whole graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(d):\n",
    "    df = pd.read_csv('../../STHN/DATA/{}/edges.csv'.format(d))\n",
    "    g = np.load('../../STHN/DATA/{}/ext_full.npz'.format(d))\n",
    "\n",
    "    return g, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data(args):\n",
    "    \"\"\"\n",
    "    Copied from train.py and modified to take a dict instead of an\n",
    "    argparse instance.\n",
    "    \"\"\"\n",
    "\n",
    "    # load graph\n",
    "    g, df = load_graph(args['data'])\n",
    "\n",
    "    args['train_edge_end'] = df[df['ext_roll'].gt(0)].index[0]\n",
    "    args['val_edge_end'] = df[df['ext_roll'].gt(1)].index[0]\n",
    "    args['num_nodes'] = max(int(df['src'].max()), int(df['dst'].max())) + 1\n",
    "    args['num_edges'] = len(df)\n",
    "    print('Train %d, Valid %d, Test %d' %\n",
    "          (args['train_edge_end'], args['val_edge_end'] - args['train_edge_end'],\n",
    "           len(df) - args['val_edge_end']))\n",
    "    print('Num nodes %d, num edges %d' % (args['num_nodes'], args['num_edges']))\n",
    "\n",
    "    # load feats\n",
    "    node_feats, edge_feats = load_feat(args['data'])\n",
    "    node_feat_dims = 0 if node_feats is None else node_feats.shape[1]\n",
    "    edge_feat_dims = 0 if edge_feats is None else edge_feats.shape[1]\n",
    "\n",
    "    # feature pre-processing\n",
    "    ## This was all False for us\n",
    "#     if args['use_onehot_node_feats']: \n",
    "#         print('>>> Use one-hot node features')\n",
    "#         node_feats = torch.eye(args['num_nodes'])\n",
    "#         node_feat_dims = node_feats.size(1)\n",
    "\n",
    "#     if args.ignore_node_feats:\n",
    "#         print('>>> Ignore node features')\n",
    "#         node_feats = None\n",
    "#         node_feat_dims = 0\n",
    "\n",
    "#     if args.use_type_feats:\n",
    "#         edge_type = df.label.values\n",
    "#         args['num_edgeType'] = len(set(edge_type.tolist()))\n",
    "#         edge_feats = torch.nn.functional.one_hot(torch.from_numpy(edge_type -\n",
    "#                                                                   1),\n",
    "#                                                  num_classes=args['num_edgeType'])\n",
    "#         edge_feat_dims = edge_feats.size(1)\n",
    "\n",
    "    print('Node feature dim %d, edge feature dim %d' %\n",
    "          (node_feat_dims, edge_feat_dims))\n",
    "\n",
    "    # double check (if data leakage then cannot continue the code)\n",
    "#     if args.check_data_leakage:\n",
    "#                 check_data_leakage(args, g, df)\n",
    "\n",
    "    args['node_feat_dims'] = node_feat_dims\n",
    "    args['edge_feat_dims'] = edge_feat_dims\n",
    "\n",
    "    if node_feats != None:\n",
    "        node_feats = node_feats.to(args['device'])\n",
    "    if edge_feats != None:\n",
    "        edge_feats = edge_feats.to(args['device'])\n",
    "\n",
    "    return node_feats, edge_feats, g, df, args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'data': 'drought_desiccation',\n",
    "    'device': 0,\n",
    "    'num_edgeType': 4,\n",
    "    'num_neighbors': 50,\n",
    "    'batch_size': 600,\n",
    "    'sampled_num_hops': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 939296, Valid 216485, Test 133433\n",
      "Num nodes 334579, num edges 1289214\n",
      "Node feature dim 0, edge feature dim 0\n"
     ]
    }
   ],
   "source": [
    "node_feats, edge_feats, g, df, args = load_all_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_compute_subgraphs(args, g, df, mode):\n",
    "    ###################################################\n",
    "\n",
    "    extra_neg_samples = 1\n",
    "\n",
    "    ###################################################\n",
    "    # for each node, sample its neighbors with the most recent neighbors (sorted) \n",
    "    print('Sample subgraphs ... for %s mode'%mode)\n",
    "    sampler, neg_link_sampler = get_parallel_sampler(g, args['num_neighbors'])\n",
    "\n",
    "    ###################################################\n",
    "    # setup modes\n",
    "    if mode == 'train':\n",
    "        cur_df = df[:args['train_edge_end']]\n",
    "\n",
    "    elif mode == 'valid':\n",
    "        cur_df = df[args['train_edge_end']:args['val_edge_end']]\n",
    "\n",
    "    elif mode == 'test':\n",
    "        cur_df = df[args['val_edge_end']:]\n",
    "        loader = cur_df.groupby(cur_df.index // args['batch_size'])\n",
    "    pbar = tqdm(total=len(loader))\n",
    "    pbar.set_description('Pre-sampling: %s mode with negative sampleds %s ...'%(mode, extra_neg_samples))\n",
    "\n",
    "    ###################################################\n",
    "    all_subgraphs = []\n",
    "    all_elabel = []\n",
    "    sampler.reset()\n",
    "    for _, rows in loader:\n",
    "\n",
    "        root_nodes = np.concatenate(\n",
    "            [rows.src.values, \n",
    "             rows.dst.values, \n",
    "             neg_link_sampler.sample(len(rows) * extra_neg_samples)]\n",
    "        ).astype(np.int32)\n",
    "\n",
    "        # time-stamp for node = edge time-stamp\n",
    "        ts = np.tile(rows.time.values, extra_neg_samples + 2).astype(np.float32)\n",
    "        all_elabel.append(rows.label.values)\n",
    "        all_subgraphs.append(get_mini_batch(sampler, root_nodes, ts, args['sampled_num_hops']))\n",
    "\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "    subgraph_elabel = (all_subgraphs, all_elabel)\n",
    "    try:\n",
    "        pickle.dump(subgraph_elabel, open(fn, 'wb'), protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    except:\n",
    "        print('For some shit reason pickle cannot save ... but anyway ...')\n",
    "\n",
    "        ###################################################\n",
    "        \n",
    "    return subgraph_elabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample subgraphs ... for test mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pre-sampling: test mode with negative sampleds 1 ...: 100%|██████████| 223/223 [06:35<00:00,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For some shit reason pickle cannot save ... but anyway ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_subgraphs = pre_compute_subgraphs(args, g, df, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraphs, elabel = test_subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict,\n",
       " dict_keys(['row', 'col', 'eid', 'nodes', 'dts', 'num_nodes', 'num_edges', 'root_node', 'root_time']))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(subgraphs[0][0]), subgraphs[0][0].keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 39\n",
      "col 39\n",
      "eid 39\n",
      "nodes 40\n",
      "dts 40\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'int' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m subgraphs[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(k, \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"
     ]
    }
   ],
   "source": [
    "for k, v in subgraphs[0][0].items():\n",
    "    print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_neg_samples = 1\n",
    "neg_samples = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'mini_batch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m subgraph_data_list \u001b[38;5;241m=\u001b[39m subgraphs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m subgraph_data \u001b[38;5;241m=\u001b[39m \u001b[43msubgraphs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmini_batch\u001b[49m(\n\u001b[1;32m      3\u001b[0m                 \u001b[38;5;241m0\u001b[39m, get_random_inds(\n\u001b[1;32m      4\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(subgraph_data_list), cached_neg_samples, neg_samples))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'mini_batch'"
     ]
    }
   ],
   "source": [
    "subgraph_data_list = subgraphs[0]\n",
    "subgraph_data = subgraphs[0].mini_batch(\n",
    "                0, get_random_inds(\n",
    "                len(subgraph_data_list), cached_neg_samples, neg_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_df_links = len(subgraph_data_list) // (cached_neg_samples + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph_node_feats = compute_sign_feats(\n",
    "                node_feats, df, args['val_edge_end'], num_of_df_links,\n",
    "                subgraph_data['root_nodes'], args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how the run command is used for test set\n",
    "run(copy.deepcopy(model),\n",
    "   None,\n",
    "   args,\n",
    "   test_subgraphs,\n",
    "   df,\n",
    "   node_feats,\n",
    "   edge_feats,\n",
    "   test_AUROC,\n",
    "   test_AUPRC,\n",
    "   mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sthn",
   "language": "python",
   "name": "sthn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
